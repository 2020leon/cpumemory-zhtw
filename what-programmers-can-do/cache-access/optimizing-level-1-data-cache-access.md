# 6.2.1. 最佳化一階資料快取存取

在 3.3 節，我們已經看過 L1d 快取的有效使用能夠提升效能。在這一節，我們會展示什麼樣的程式碼改變能夠協助改進這個效能。延續前一節，我們首先聚焦在循序存取記憶體的最佳化。如同在 3.3 節中看到的數字，處理器在記憶體被循序存取的時候會自動預取資料。

使用的範例程式碼為矩陣乘法。我們使用兩個 $$ 1000 \times 1000 $$ `double` 元素的方陣（square matrices）。對於那些忘記數學的人，給定元素為 $$ a_{ij} $$ 與 $$ b_{ij} $$ 的矩陣 $$ A $$ 與 $$ B $$，$$ 0 \leq i,j < N $$，乘積為

$$
(AB)_{ij} = \sum^{N - 1}_{k = 0} a_{ik} b_{kj} = a_{i1} b_{1j} + a_{i2} b_{2j} + \cdots + a_{i(N - 1)} b_{(N - 1)j}
$$

一個直觀的 C 實作看起來可能像這樣

```c
for (i = 0; i < N; ++i)
  for (j = 0; j < N; ++j)
    for (k = 0; k < N; ++k)
      res[i][j] += mul1[i][k] * mul2[k][j];
```

兩個輸入矩陣為 `mul1` 與 `mul2`。假定結果矩陣 `res` 全被初始化為零。這是個既好又簡單的實作。但應該很明顯的是，我們有個正好是在圖 6.1 解釋過的問題。在 `mul1` 被循序存取的時候，內部的迴圈增加了 `mul2` 的列號。這表示 `mul1` 是像圖 6.1 中左邊的矩陣那樣處理，而 `mul2` 是像右邊的矩陣那樣處理。這可能不太好。

有一個能夠輕易嘗試的可能補救方法。由於矩陣中的每個元素會被多次存取，是值得在使用第二個矩陣 `mul2` 之前將它重新排列（數學術語的話，「轉置〔transpose〕」）的。

$$
(AB)_{ij} = \sum^{N - 1}_{k = 0} a_{ik} b^{\text{T}}_{jk} = a_{i1} b^{\text{T}}_{j1} + a_{i2} b^{\text{T}}_{j2} + \cdots + a_{i(N - 1)} b^{\text{T}}_{j(N - 1)}
$$

在轉置之後（通常以上標「T」表示），我們現在循序地疊代兩個矩陣。就 C 程式而言，現在看起來像這樣：

```c
double tmp[N][N];
for (i = 0; i < N; ++i)
  for (j = 0; j < N; ++j)
    tmp[i][j] = mul2[j][i];
for (i = 0; i < N; ++i)
  for (j = 0; j < N; ++j)
    for (k = 0; k < N; ++k)
      res[i][j] += mul1[i][k] * tmp[j][k];
```

我們建立一個容納被轉置的矩陣的暫時變數（temporary variable）。這需要動到額外的記憶體，但這個成本會被––希望如此––彌補回來，因為每行 1000 次非循序存取是更為昂貴的（至少在現代的硬體上）。是進行一些效能測試的時候了。在有著 2666MHz 時脈的 Intel Core 2 上的結果為（以時鐘週期為單位）：

<table>
  <tr>
    <th></th>
    <th>原始</th>
    <th>轉置</th>
  </tr>
  <tr>
    <th>週期數</th>
    <td>16,765,297,870</td>
    <td>3,922,373,010</td>
  </tr>
  <tr>
    <th>相對值</th>
    <td>100%</td>
    <td>23.4%</td>
  </tr>
</table>

雖然只是個簡單的矩陣轉置，但我們能達到 76.6% 的加速！複製操作的損失完全被彌補了。1000 次非循序存取真的很傷。

下個問題是，我們是否能做得更好。無論如何，我們確實需要一個不需額外複製的替代方法。我們並不是總有餘裕能進行複製：矩陣可能太大、或者可用的記憶體太小。

替代實作的探尋應該從徹底地檢驗涉及到的數學與原始實作所執行的操作開始。簡單的數學知識讓我們能夠發現，只要每個加數（addend）正好出現一次，對結果矩陣的每個元素執行的加法順序是無關緊要的。[^28]這個理解讓我們能夠尋找將執行在原始程式碼內部迴圈的加法重新排列的解法。

現在，讓我們來檢驗在原始程式碼執行中的實際問題。被存取的 `mul2` 元素的順序為：$$ (0, 0) $$、$$ (1, 0) $$、 ... 、$$ (N - 1, 0) $$、$$ (0,1) $$、$$ (1, 1) $$、 ...。元素 $$ (0, 0) $$ 與 $$ (0, 1) $$ 位於同一個快取行中，但在內部迴圈完成一輪的時候，這個快取行早已被逐出了。以這個例子而言，每一輪內部迴圈都需要––對三個矩陣的每一個而言––1000 個快取行（Core 2 處理器為 64 位元組）。這加起來遠比 L1d 可用的 32k 還多。

但若是我們在執行內部迴圈的期間，一起處理中間迴圈的兩次疊代呢？在這個情況下，我們使用兩個來自必定在 L1d 中的快取行的 `double` 值。我們將 L1d 錯失率減半了。[^譯註]這當然是個改進，但––視快取行的大小而定––也許仍不是我們能夠得到的最好結果。Core 2 處理器有個快取行大小為 64 位元組的 L1d。實際的大小能夠使用

`sysconf (_SC_LEVEL1_DCACHE_LINESIZE)`

在執行期查詢、或是使用命令列（command line）的 `getconf` 工具程式（utility），以讓程式能夠針對特定的快取行大小編譯。以 `sizeof(double)` 為 8 來說，這表示––為了完全利用快取行––我們應該展開內部迴圈 8 次。繼續這個想法，為了有效地使用 `res` 矩陣––即，為了同時寫入 8 個結果––我們也該展開外部迴圈 8 次。我們假設這裡的快取行大小為 64，但這個程式碼也能在 32 位元組快取行的系統上運作，因為快取行也會被 100% 利用。一般來說，最好在編譯期像這樣使用 `getconf` 工具程式來寫死（hardcode）快取行大小：

`gcc -DCLS=$(getconf LEVEL1_DCACHE_LINESIZE) ...`

If the binaries are supposed to be generic, the largest cache line size should be used.
使用非常小的 L1d 表示並非所有資料都能塞進快取，但這種處理器無論如何都不適合高效能程式。我們寫出的程式碼看起來像這樣：

```c
#define SM (CLS / sizeof (double))
for (i = 0; i < N; i += SM)
  for (j = 0; j < N; j += SM)
    for (k = 0; k < N; k += SM)
      for (i2 = 0, rres = &res[i][j],
           rmul1 = &mul1[i][k]; i2 < SM;
           ++i2, rres += N, rmul1 += N)
        for (k2 = 0, rmul2 = &mul2[k][j];
             k2 < SM; ++k2, rmul2 += N)
          for (j2 = 0; j2 < SM; ++j2)
            rres[j2] += rmul1[k2] * rmul2[j2];
```

這看起來超可怕的。在某種程度上它是如此，但只是因為它包含了一些技巧。最顯而易見的改變是，我們現在有六層巢狀迴圈了。外部迴圈以 `SM`（快取行大小除掉 `sizeof(double)`）為間隔疊代。這將乘法切成多個能夠以更多快取局部性處理的較小的問題。內部迴圈疊代外部迴圈漏掉的索引。再一次，這裡有三層迴圈。這裡唯一巧妙的部分是 `k2` 與 `j2` 迴圈的順序不同。這是因為在實際運算中，僅有一個表示式取決於 `k2`、但有兩個取決於 `j2`。

這裡其餘的複雜之處來自 gcc 在最佳化陣列索引的時候並不是非常聰明的結果。額外變數 `rres`、`rmul1`、與 `rmul2` 的引入，藉由將內部迴圈的常用表示式（expression）盡可能地拉出來，以最佳化程式碼。C 與 C++ 語言預設的別名規則（aliasing rule）並不能幫助編譯器做出這些決定（除非使用 `restrict`，所有指標存取都是別名的潛在來源）。這即是為何對於數值程式設計而言，Fortran 仍是一個偏好語言的原因：它令快速程式的撰寫更簡單。[^29]

<figure>
  <table>
    <tr>
      <th></th>
      <th>原始</th>
      <th>轉置</th>
      <th>子矩陣</th>
      <th>向量化</th>
    </tr>
    <tr>
      <th>週期數</th>
      <td>16,765,297,870</td>
      <td>3,922,373,010</td>
      <td>2,895,041,480</td>
      <td>1,588,711,750</td>
    </tr>
    <tr>
      <th>相對值</th>
      <td>100%</td>
      <td>23.4%</td>
      <td>17.3%</td>
      <td>9.47%</td>
    </tr>
  </table>
  <figcaption>表 6.2：矩陣乘法計時</figcaption>
</figure>

所有努力所帶來的成果能夠在表 6.2 看到。藉由避免複製，我們增加了額外的 6.1% 效能。此外，我們不需要任何額外的記憶體。只要結果矩陣也能塞進記憶體，輸入矩陣可以是任意大小的。這是我們現在已經達成的一個通用解法的一個必要條件。

在表 6.2 中還有一欄沒有被解釋過。大多現代處理器現今包含了針對向量化（vectorization）的特殊支援。經常被標為多媒體擴充，這些特殊指令能夠同時處理 2、4、8、或者更多值。這些經常是 SIMD（單指令多資料，Single Instruction, Multiple Data）操作，藉由其它操作的協助，以便以正確的形式獲取資料。由 Intel 處理器提供的 SSE2 指令能夠在一個操作中處理兩個 `double` 值。指令參考手冊列出了提供對這些 SSE2 指令存取的內建函數。若是用了這些內建函數，程式執行會變快 7.3%（相對於原始實作）。結果是，一支以原始程式碼 10% 的時間執行的程式。翻譯成人們認識的數字，我們從 318 MFLOPS 變為 3.35 GFLOPS。由於我們在這裡僅對記憶體的影響有興趣，程式的原始碼被擺到了 A.1 節。

應該注意的是，在最後一版的程式碼中，我們仍然有一些 `mul2` 的快取問題；預取仍然無法運作。但這無法在不轉置矩陣的情況下解決。或許快取預取單元將會變得聰明地足以識別這些模式，那時就不需要額外的更動了。不過，以一個 2.66 GHz 處理器上的單執行緒程式而言，3.19 GFLOPS 並不差了。

我們在矩陣乘法的例子中最佳化的是被載入的快取行的使用。一個快取行的所有位元組總是會被用到。我們只是確保在快取行被逐出前會用到它們。這當然是個特例。

更常見的是，擁有塞滿一或多個快取行的資料結構，而程式在任何時間點都只會使用幾個成員。我們已經在圖 3.11 看過，大結構尺寸在只有一些成員被用到時的影響。

<figure>
  <img src="../../assets/figure-6.2.png" alt="圖 6.2：散布在多個快取行中">
  <figcaption>圖 6.2：散布在多個快取行中</figcaption>
</figure>

圖 6.2 顯示了使用現在已熟知的程式執行另一組基準測試的結果。這次會加上同個串列元素的兩個值。在一個案例中，兩個元素都在同一個快取行內；在另一個案例中，一個元素位在串列元素的第一個快取行，而第二個位在最後一個快取行。這張圖顯示了我們正遭受的效能衰減。

不出所料，在所有情況下，若是工作集塞得進 L1d 就不會有任何負面影響。一旦 L1d 不再充足，則是使用一個行程的兩個快取行來償付損失，而非一個。紅線顯示了串列被循序地排列時的數據。我們看到尋常的兩步模式：當 L2 快取充足時的大約 17% 的損失、以及當必須用到主記憶體時的大約 27% 的損失。

在隨機記憶體存取的情況下，相對的數據看起來有點不同。對於塞得進 L2 的工作集而言的效能衰減介於 25% 到 35% 之間。再往後它下降到了大約 10%。這不是因為損失變小了，而是因為實際的記憶體存取不成比例地變得更昂貴了。這份數據也顯示了，在某些情況下，元素之間的距離是很重要的。Random 4 CLs 的曲線顯示了較高的損失，因為用到了第一個與第四個快取行。

（本節未完）



[^28]: 我們這裡忽略了可能會改變上溢位（overflow）、下溢位（underflow）、或是四捨五入（rounding）的發生的算術影響。

[^譯註]: 這裡可能講得比較抽象。作者的意思是：在一開始三層迴圈的實作中，最內部的每一次 `k` 迴圈疊代同時處理 `res[i][j] += mul1[i][k] * mul2[k][j]` 與 `res[i][j + 1] += mul1[i][k] * mul2[k][j + 1]`。由於才剛存取過 `mul2[k][j]` 與 `res[i][j]`，所以 `mul2[k][j + 1]` 與 `res[i][j + 1]` 還在 L1d 快取中，因而降低了錯失率。後述的方法是這個方法的一般化（generalization）。

[^29]: 理論上在 1999 修訂版引入 C 語言的 `restrict` 關鍵字應該解決這個問題。不過編譯器還是不理解。原因主要是存在著太多不正確的程式碼，其會誤導編譯器、並導致它產生不正確的目的碼（object code）。

